{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping TV-shows on TMDB using python.\n",
    "\n",
    "\n",
    "- The Movie Database (TMDB) is a community built movie and TV database.Also provides an API portal for \n",
    "researchers who wants access to movie data.\n",
    "- https://www.themoviedb.org/tv this page provides us list of popular TV shows on TMDB, let's retrive information from this page using _web scrapping_.We are going to use Requests and Beautiful Soup to scrap data from this page.\n",
    "\n",
    "![web1.png](https://i.imgur.com/HQBMrPp.png)\n",
    "\n",
    "- After opening the website, we are going to navigate through the Tvshows tab on the top left and click on option popular to get the page of popular Tv shows. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here are the steps we'll follow:\n",
    "\n",
    "- We're going to scrape https://www.themoviedb.org/tv\n",
    "- First step would be to download the webpage using `requests`.\n",
    "- Parse the HTML source code using `Beautifulsoup`.\n",
    "- We'll check out the page that has the list of TV-shows. For each show, we'll extract title, User Score, show's individual page URL and the premiered date.\n",
    "- From each individual page URL, we'll extract different kind of information about the show. For each page, we'll grab the Current_season, Current_season_Episodes, Tagline, Genre, and Cast.\n",
    "- Compile extracted information into python lists and dictionaries.\n",
    "- Extract and combine data from multiple pages.\n",
    "- Finally, we are going to save the extracted information to a CSV file.\n",
    "\n",
    "\n",
    ":- Following is the format for how our data will look like in the tabular form after extraction:\n",
    "\n",
    "\n",
    "Title, | User_rating, | Release_date, |Current_season, |Current_season_Episodes,| Tagline,| Genre,| Cast\n",
    ":------ | :---------- | :----------- | :------------ | :----------------------|:-------|:-----|:--- \n",
    "The Snitch Cartel: Origins, |81.0, |\"Jul 28, |2021\", |Season 1, |60 Episodes,No Tagline, |\"['Crime', 'Soap']\", |['Juan Pablo Urrego']\n",
    "Noovo Le Fil Québec, |Not rated yet, |\"Mar 29, 2021\", |Season 1, |110 Episodes, |No Tagline, |['News'], |['Lisa-Marie Blais']\n",
    "\n",
    "- Fo|r each TV-show we'll create a CSV file in the following format:\n",
    "\n",
    "   1. Title, User_rating, Release_date, Current_season, Current_season_Episodes, Tagline, Genre, Cast\n",
    "   2. The Snitch Cartel: Origins, 81.0, \"Jul 28,  2021\", Season 1, 60 Episodes, No Tagline, \"['Crime', 'Soap']\", ['Juan Pablo Urrego']\n",
    "   3. Noovo Le Fil Québec, Not rated yet, \"Mar 29, 2021\", Season 1, 110 Episodes, No Tagline, ['News'], ['Lisa-Marie Blais']\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the webpage using `requests` \n",
    "Let's visit the website first and then we can examin the information we need. Following are the steps we will take to get the information and put into a proper format.\n",
    "\n",
    "- use `requests` library to downlaod the web page. The library can be installed using `pip`.\n",
    "\n",
    "To download a page , we can use the `get` function from requests, which returns a response object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# The library is now installed and imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sometimes websites stop you from extracting the data for some reason. It can be due to some authentication errors.\n",
    "\n",
    "needed_headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36\"}\n",
    "response = requests.get(\"https://www.themoviedb.org/tv\", headers = needed_headers )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requests.get` returns a response object containing the data from the web page and some other information.\n",
    "\n",
    "The `.status_code` can be used to check if the response was successful. A successful response will have an [HTTP status code] (https://developer.mozilla.org/en-US/docs/Web/HTTP/Status) between 200 and 299."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The request was successful. We can get the contents of the page using `response.text`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189176"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwn_content = response.text\n",
    "len(dwn_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the page has 189176 characters in total. \n",
    "\n",
    "Lets take a look at first 500 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\" class=\"no-js\">\\n  <head>\\n    <title>Popular TV Shows &#8212; The Movie Database (TMDB)</title>\\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" />\\n    <meta http-equiv=\"cleartype\" content=\"on\">\\n    <meta charset=\"utf-8\">\\n    \\n    <meta name=\"keywords\" content=\"Movies, TV Shows, Streaming, Reviews, API, Actors, Actresses, Photos, User Ratings, Synopsis, Trailers, Teasers, Credits, Cast\">\\n    <meta name=\"mobile-web-app-capable\" content=\"yes\">\\n    <meta name=\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dwn_content[:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what we are looking above is the [HTML source code](https://en.wikipedia.org/wiki/HTML) of the web page in the form of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the HTML source code using beautiful soup.\n",
    "\n",
    "- use `BS4` to import the BeautifulSoup library.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To parse the HTML source code we are going to use `BeautifulSoup()` function that takes two arguments.  \n",
    " - content of the page.\n",
    " - 'html.parser'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_doc = BeautifulSoup(dwn_content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(test_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Popular TV Shows — The Movie Database (TMDB)</title>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc.find('title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<img alt=\"The Movie Database (TMDB)\" height=\"20\" src=\"/assets/2/v4/logos/v2/blue_short-8e7b30f73a4020692ccca9c88bafe5dcb6f8a62a4c6bc55cd9ba82bb2cd95f6c.svg\" width=\"154\"/>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_doc.find('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " With all the information we have so far, let's create a function that will download a web page by using `request` and `BeautifulSoup`. Returns a beautifulSoup type object for any given link."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_page_content(url):\n",
    "    # In this case , we are going to give request.get function headers to avoid the Status code Error 403\n",
    "\n",
    "    get_headers = {'User-Agent': \"Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36\"}\n",
    "    response_page = requests.get(url, headers = get_headers )\n",
    "    # we are going to raise exception here if status code gives any value other than 200.\n",
    "    if not response_page.ok:\n",
    "        raise Exception (\"Failed to request the data. Status Code:- {}\".format(response_page.status_code))\n",
    "    else:\n",
    "        page_content = response_page.text\n",
    "        doc_page = BeautifulSoup(page_content, \"html.parser\")\n",
    "        return doc_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "popular_shows_url = \"https://www.themoviedb.org/tv\"\n",
    "doc = get_page_content(popular_shows_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Popular TV Shows — The Movie Database (TMDB)'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#let's try to get the title of the page to check if our function works. \n",
    "\n",
    "doc.title.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create some helper functions to parse information from the page.\n",
    "\n",
    "To get show's titles and premiered date, we can pick 'h2' and 'p' tags  respectively with the class 'card style_1' ...\n",
    "\n",
    "![Web 2.png](https://i.imgur.com/JFyb88G.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chucky'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now that we know the class let's trty to get the title of the first movie. \n",
    "\n",
    "doc.find_all('div', {'class': 'card style_1'})[0].h2.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For premiered date we just need to change the tag that is 'p' tag because it also comes under class 'card style_1\n",
    "- Similarly, we can get the user rating of the show with the help of class \"user_score_chart\" and then we can get the value of attribute \"data-percent\".\n",
    " \n",
    " Below is the example to get user rating of first movie which we just extracted above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'80'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find_all('div', {'class': 'user_score_chart'})[0]['data-percent']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to create a dictionary that will have the name of the columns of our CSV file in the form of keys, and the values would be the data that we are going to _scrape/extract_ from the web page. It is simply a dict type vairable in python that is going to store all of our data which we will use to create _Dataframe_ and  _CSV_ later  on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def empty_dict():\n",
    "    scraped_dict = {  \n",
    "                    'Title': [],\n",
    "                    'User_rating': [], \n",
    "                    'Release_date':[], \n",
    "                    'Current_season': [],\n",
    "                    'Current_season_Episodes': [], \n",
    "                    'Tagline': [],\n",
    "                    'Genre': [],\n",
    "                    'Cast': []   \n",
    "                    }\n",
    "    return scraped_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we observe multiple shows, we will realize that not every show has been rated yet. \n",
    "- Let's create a function to deal with this problem. If a show is not rated yet, we can skip it or make it display a message. \n",
    "- The function will parse the user score into a dictionary. The function will come handy later on when we need to create a final function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_score_info(tag_user_score, i, scraped_dict):\n",
    "    if tag_user_score[i]['data-percent'] == '0':\n",
    "        scraped_dict['User_rating'].append('Not rated yet')\n",
    "    else:\n",
    "        scraped_dict['User_rating'].append(tag_user_score[i]['data-percent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One more information that we need from this page is the url to get to the individual page of the Show, so that we can get the rest of the information.\n",
    "\n",
    "This can be achieved from the class \"card style_1\" as well, we just need to get the value of attribute \"href\" in the h2 tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tv/90462'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.find_all('div', {'class': 'card style_1'})[0].h2.a['href']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we have all the information that we need from this page. Let's put it all together in one function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_show_info(doc_page):\n",
    "    base_link_1 = \"https://www.themoviedb.org\"\n",
    "    tag_title = tag_premired_date = tag_shows_page = doc_page.find_all('div', {'class': 'card style_1'})\n",
    "    tag_user_score = doc_page.find_all('div', {\"user_score_chart\"}) \n",
    "    \n",
    "    doc_2_list = []\n",
    "    for link in tag_shows_page:\n",
    "        # here we are creating the list of all the individual pages of the shows which will come handy in other functions. \n",
    "        doc_2_list.append(get_page_content(\"https://www.themoviedb.org\" + link.h2.a['href']))\n",
    "       # we are going to have the function to return the list of all the information as elements. \n",
    "    return tag_title, tag_user_score, doc_2_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets see if the function returns the list of the information we tried to get earlier. \n",
    "len(get_show_info(doc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Lets scrape Current_season, Current_season_Episodes, Tagline, Genre, Cast.\n",
    " \n",
    " - From the list of the shows individual webpages we will try to get Current_season, Current_season_Episodes, Tagline, Genre, Cast.\n",
    "  - Let's get the Genre of the Show and tagline. The classes we are going to use for this are \"genres\" and \"tagline\". Take a look at the image down below for better understanding.   \n",
    "![web 3.png](https://i.imgur.com/PL4xjM9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets download and get the html of the individual page of the show 'what if...?' with the function get_page_content(). \n",
    "doc_2 = get_page_content(\"https://www.themoviedb.org/tv/91363\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see 'a' tag under class 'genres' contains different values for the genre of the show. let's create a list of genres .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Animation', 'Action & Adventure', 'Sci-Fi & Fantasy']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_genre = doc_2.find('span', {\"class\": \"genres\"})\n",
    "tag_genre_list = tag_genre.find_all('a')\n",
    "\n",
    "check_genre =[]\n",
    "for tag in tag_genre_list:\n",
    "    check_genre.append(tag.text)\n",
    "\n",
    "check_genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a function to get the genres for the show. \n",
    "# i here denotes the element of the list vairable ``doc2_page`` that contains different doc pages. Will come handy later on.\n",
    "def get_genres(doc2_page, i):\n",
    "    genres_tags = doc2_page[i].find('span', {\"class\": \"genres\"}).find_all('a')\n",
    "    check_genre =[]\n",
    "    \n",
    "    for tag in genres_tags:\n",
    "        check_genre.append(tag.text)\n",
    "    return check_genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For the next piece of information we need Tagline of the show but, for some movies it is not yet available.\n",
    "- Let's create a function for this and tackle this problem simply using if else statements.\n",
    "- The function will parse the value into a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_tagline = doc_2.find('h3',{\"class\": 'tagline'})\n",
    "\n",
    "def tagline_info(doc_2_list, i, scraped_dict):\n",
    "    if doc_2_list[i].find('h3',{\"class\": 'tagline'}):\n",
    "        scraped_dict['Tagline'].append(doc_2_list[i].find('h3',{\"class\": 'tagline'}).text)\n",
    "    else:\n",
    "        scraped_dict['Tagline'].append(\"No Tagline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just like we got the list of genres and then a function for it, if we inspect the HTML of TV show's wepbage, we can get the list of cast with the help of class 'card' and tag 'li'. \n",
    "\n",
    "![image5.png](https://i.imgur.com/vx1BxX2.png)\n",
    "\n",
    "\n",
    "\n",
    "Let's create a function to get the cast of the show. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i here denotes the the element of the list type variable``doc2_page`` that contains different doc pages.\n",
    "\n",
    "def get_show_cast(doc2_page, i):\n",
    "    cast_tags = doc2_page[i].find_all('li', {'class': 'card'})\n",
    "    cast_lis = []\n",
    "    \n",
    "    for t in cast_tags:\n",
    "         cast_lis.append(t.p.text)\n",
    "    \n",
    "    return cast_lis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - For few last pieces of information we are going to scrape 'current_season' and its episodes. We can access it under class \"flex\".  \n",
    " ![web 5.png](https://i.imgur.com/PQGeBQk.png)\n",
    " \n",
    " - For the \"current_season\" it is pretty easy and simple, we just have to get the text part of \"h2\" tag. \n",
    " - But, if we look closely in the image above, we can see for the current seasons episodes it gets little tricky as we also have the year mentioned in front of number of the episodes. \n",
    " - we are going to cut that part off so that we are left with just the number of episodes. check out the cells below for better understating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Season 1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_episodes = doc_2.find_all('div' , {'class': 'flex'})\n",
    "# extracing current season from h2 tag under class flex.\n",
    "tag_episodes[1].h2.text "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As we can see in the code cell below, it not just returns the number of episodes but also the year of its making along with it. \n",
    "- This format is same for each and every show on the website. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2021 | 9 Episodes'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_episodes[1].h4.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's take the year part out. Thanks to list slicing it becomes very easy. \n",
    "- The \"h4\" tag under the class \"flex\" returns string on which 7th index marks the begining of the number of episodes. \n",
    "- This is same with each and every show on the website \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 Episodes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'9 Episodes'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('2021 | 9 Episodes'[7:])\n",
    "\n",
    "tag_episodes[1].h4.text[7:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we know how to get all the information we need from a TV-show. Lets create a function that extract all the information and returns a Dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def get_show_details(t_title, t_user_score, docs_2_list):\n",
    "    # excuting a function here that empties the dictionary every time the function is called.\n",
    "    scraped_dict =  empty_dict()\n",
    "    for i in range (0, len(t_title)):\n",
    "        scraped_dict['Title'].append(t_title[i].h2.text)\n",
    "        user_score_info(t_user_score, i, scraped_dict)    \n",
    "        scraped_dict['Release_date'].append(t_title[i].p.text)\n",
    "        scraped_dict['Current_season'].append(docs_2_list[i].find_all('div' , {'class': 'flex'})[1].h2.text)\n",
    "        scraped_dict['Current_season_Episodes'].append(docs_2_list[i].find_all('div' , {'class': 'flex'})[1].h4.text[7:])\n",
    "        tagline_info(docs_2_list, i, scraped_dict)  \n",
    "        scraped_dict['Genre'].append(get_genres(docs_2_list, i))        \n",
    "        scraped_dict['Cast'].append(get_show_cast(docs_2_list, i))\n",
    "        \n",
    "    return pd.DataFrame(scraped_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- we are going to try to execute our function\n",
    "- but, before that we need to get the values that the function will take as arguments. Which is the information from first page. \n",
    "- get_show_info() is the function we created before so that we get the information from first page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_title_, tag_user_score_, doc_2_list_ = get_show_info(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we execute our function `get_show_details()` we must understand how to create a _CSV_ file for this. Fortunately, it is really simple in python, We just have to call a function `.to_csv('path/csv_file_name')` on a dataframe.\n",
    "\n",
    "Every file has to be stored in a directory that has a path, and if the path is not given to the `.to_csv()` it will take default path of your system. In this jypiter notebook, we just have to click on the file option on top left corner and open the file system, there we will be able to view or edit our files. Look at the picture below to have understand better.\n",
    "\n",
    "\n",
    "In our case the function `get_show_details()` returns the dataframe which we are going to convert in to _CSV_ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_score_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3136/1561823053.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Let's excute our function to check if it works. We are going to take a look the data of dataframe.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_show_details\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtag_title_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtag_user_score_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdoc_2_list_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'check.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'check.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_3136/4198834503.py\u001b[0m in \u001b[0;36mget_show_details\u001b[1;34m(t_title, t_user_score, docs_2_list)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_title\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mscraped_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0muser_score_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_user_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscraped_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mscraped_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Release_date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_title\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mscraped_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Current_season'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs_2_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'div'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'class'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'flex'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mh2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'user_score_info' is not defined"
     ]
    }
   ],
   "source": [
    "# Let's excute our function to check if it works. We are going to take a look the data of dataframe.\n",
    "\n",
    "x = get_show_details(tag_title_, tag_user_score_, doc_2_list_)\n",
    "x.to_csv('check.csv')\n",
    "pd.read_csv('check.csv',index_col=[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To work with directories and files, we are going to import `OS` so that we can create or remove specific directories in our system. We can create a directory for our CSV files by using `.makedirs('directory_name', exist_ok = True)`.\n",
    "- Now, we are going to create a function that is going to take a empty list, create a dataframe and  convert it into a CSV file and save it in a folder.\n",
    "- The function will append the dataframe in the list.\n",
    "- Now, this function will use the different functions we created and scrape the shows from the page which is normally not visible on the site until we click on a button that is supposed to load the list of the shows on the next page. \n",
    "- To do so, we need to add  \" _**?page = page_number**_ \"  at the end of the url.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "base_link = \"https://www.themoviedb.org/tv\"\n",
    "\n",
    "# 'i' here means the number of page we want to extract\n",
    "def create_page_df( i, dataframe_list):\n",
    "    os.makedirs('shows-data', exist_ok = True)\n",
    "    next_url = base_link + '?page={}'.format(i)\n",
    "    doc_top = get_page_content(next_url)\n",
    "    name_tag, viewer_score_tag, doc_2_lis = get_show_info(doc_top)\n",
    "    print('scraping page {} :- {}'.format(i, next_url))\n",
    "    dataframe_data = get_show_details(name_tag, viewer_score_tag, doc_2_lis)\n",
    "    dataframe_data.to_csv(\"shows-data/shows-page-{}.csv\".format(i) , index = None)\n",
    "    print(\" ---> a CSV file with name shows-page-{}.csv has been created\".format(i))\n",
    "    dataframe_list.append(dataframe_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = []\n",
    "create_page_df(9 , test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far, we are able to extract the information and put in a CSV file. Lets look at the last few steps we need.\n",
    "\n",
    "Last step that we need to finish our fuction is to create a final CSV file that is going to take all 200 shows. \n",
    "\n",
    "- In the final function, we will take a list of  dataframes and convert it into _CSV_ with the help of **_`concat()`_** function.\n",
    "- `concat()` function takes a list of dataframes and convert it into a one big dataframe Which can be further converted into a _CSV_  file.\n",
    "-  we can scrape hundereds of shows but, we are going to scrape top 200 just to keep it clean and simple. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "base_link = \"https://www.themoviedb.org/tv\"\n",
    "\n",
    "def scrape_top_200_shows(base_link):\n",
    "    dataframe_list = []\n",
    "    # we are going to keep range up to 11 because we just need up to 200 TV shows for now. \n",
    "    for i in range(1,11):\n",
    "        create_page_df(i, dataframe_list)\n",
    "    # here we are using concat function so that we can merge the each dataframe that we got from the each page.    \n",
    "    total_dataframe = pd.concat(dataframe_list, ignore_index = True)\n",
    "    \n",
    "    # with the simple command of to_csv() we can create a csv file of all the pages we extracted.\n",
    "    csv_complete =  total_dataframe.to_csv('shows-data/Total-dataframe.csv', index= None)\n",
    "    print(\" \\n a CSV file named Total-dataframe.csv with all the scraped shows has been created\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now that are done with all the functions, let's put our final function to test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_top_200_shows(base_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We were successfully able to create a function and all the csv files we needed. let's just  take a final look at how our data looks like with the help of pandas  `.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>User_rating</th>\n",
       "      <th>Release_date</th>\n",
       "      <th>Current_season</th>\n",
       "      <th>Current_season_Episodes</th>\n",
       "      <th>Tagline</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chucky</td>\n",
       "      <td>80</td>\n",
       "      <td>Oct 12, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>A classic coming of rage story.</td>\n",
       "      <td>['Sci-Fi &amp; Fantasy', 'Comedy', 'Crime']</td>\n",
       "      <td>['Brad Dourif', 'Zackary Arthur', 'Teo Briones...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Price Is Right</td>\n",
       "      <td>67.0</td>\n",
       "      <td>Sep 04, 1972</td>\n",
       "      <td>Season 50</td>\n",
       "      <td>50 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Bob Barker', 'Johnny Olson', 'Drew Carey', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rachael Ray</td>\n",
       "      <td>53.0</td>\n",
       "      <td>Sep 18, 2006</td>\n",
       "      <td>Season 16</td>\n",
       "      <td>45 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Talk']</td>\n",
       "      <td>['Rachael Ray', 'Ian Smith', 'Gretta Monahan',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wheel of Fortune</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Sep 19, 1983</td>\n",
       "      <td>Season 39</td>\n",
       "      <td>50 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Family']</td>\n",
       "      <td>['Pat Sajak', 'Vanna White', 'Bob Goen', 'Chuc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Squid Game</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Sep 17, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>9 Episodes</td>\n",
       "      <td>45.6 billion won is child's play.</td>\n",
       "      <td>['Action &amp; Adventure', 'Mystery', 'Drama']</td>\n",
       "      <td>['Lee Jung-jae', 'Park Hae-soo', 'Jung Ho-yeon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Days of Our Lives</td>\n",
       "      <td>63.0</td>\n",
       "      <td>Nov 08, 1965</td>\n",
       "      <td>Season 57</td>\n",
       "      <td>45 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Soap', 'Drama']</td>\n",
       "      <td>['Deidre Hall', 'Bryan Dattilo', 'Alison Sween...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wer weiß denn sowas?</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Jul 06, 2015</td>\n",
       "      <td>Season 7</td>\n",
       "      <td>35 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Reality', 'Family']</td>\n",
       "      <td>['Kai Pflaume', 'Bernhard Hoëcker', 'Elton', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maradona: Blessed Dream</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Oct 29, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Documentary']</td>\n",
       "      <td>['Julieta Cardinali', 'Juan Palomino', 'Merced...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Alix and the Marvelous</td>\n",
       "      <td>Not rated yet</td>\n",
       "      <td>Sep 09, 2019</td>\n",
       "      <td>Season 3</td>\n",
       "      <td>54 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Family', 'Sci-Fi &amp; Fantasy', 'Drama']</td>\n",
       "      <td>['Rosalie Daoust', 'Jean-Philippe Lehoux', 'Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>70</td>\n",
       "      <td>Sep 10, 1984</td>\n",
       "      <td>Season 38</td>\n",
       "      <td>50 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Alex Trebek', 'Ken Jennings', 'Brad Rutter',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Meet</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Aug 23, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>80 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Soap']</td>\n",
       "      <td>['Ashi Singh', 'Shagun Pandey', 'Vaishnavi Mac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Haireta mou ton Platano</td>\n",
       "      <td>60</td>\n",
       "      <td>Oct 12, 2020</td>\n",
       "      <td>Season 2</td>\n",
       "      <td>40 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>['Tasos Halkias', 'Pinelopi Plaka', 'Thodoris ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Out Of The Dream</td>\n",
       "      <td>20</td>\n",
       "      <td>Oct 28, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>30 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>['Zeawo', 'Yusi Chen', 'Fu Jing', 'Xie Xingyan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Invasion</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Oct 21, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>Hold on to your humanity.</td>\n",
       "      <td>['Sci-Fi &amp; Fantasy', 'Drama']</td>\n",
       "      <td>['Sam Neill', 'Golshifteh Farahani', 'Shiori K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lucifer</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Jan 25, 2016</td>\n",
       "      <td>Season 6</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>All bad things must come to an end.</td>\n",
       "      <td>['Crime', 'Sci-Fi &amp; Fantasy']</td>\n",
       "      <td>['Tom Ellis', 'Lauren German', 'Kevin Alejandr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Ricardo</td>\n",
       "      <td>22.0</td>\n",
       "      <td>Sep 09, 2002</td>\n",
       "      <td>Season 20</td>\n",
       "      <td>55 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Family', 'Talk']</td>\n",
       "      <td>['Ricardo Larrivée', 'Hélène Laurendeau', 'Pie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The All-Round Wife</td>\n",
       "      <td>57.0</td>\n",
       "      <td>Oct 04, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>120 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Family']</td>\n",
       "      <td>['kim jae-in', 'Han Da-gam', 'Geum Bo-ra', 'Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Marry Me, Marry You</td>\n",
       "      <td>50</td>\n",
       "      <td>Sep 13, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>45 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Comedy']</td>\n",
       "      <td>['Janine Gutierrez', 'Paulo Avelino', 'Sunshin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>The Good Doctor</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Sep 25, 2017</td>\n",
       "      <td>Season 5</td>\n",
       "      <td>7 Episodes</td>\n",
       "      <td>His mind is a mystery, his methods are a miracle.</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>['Freddie Highmore', 'Richard Schiff', 'Hill H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>A Thousand Fangs</td>\n",
       "      <td>76.0</td>\n",
       "      <td>Oct 28, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>7 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Action &amp; Adventure']</td>\n",
       "      <td>['Claudio Cataño', 'Alejandro Buitrago', 'Hect...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Al Hayba</td>\n",
       "      <td>63.0</td>\n",
       "      <td>May 27, 2017</td>\n",
       "      <td>Jabal</td>\n",
       "      <td>30 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Action &amp; Adventure']</td>\n",
       "      <td>['Tim Hassan', 'Mona Wassef', 'Abdo Shahin', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Se xena kheria</td>\n",
       "      <td>20</td>\n",
       "      <td>Sep 27, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>34 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>['Giannis Bezos', 'Gerasimos Skiadaresis', 'Re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ghum Hai Kisi Ke Pyaar Mein</td>\n",
       "      <td>100</td>\n",
       "      <td>Oct 05, 2020</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>352 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Soap', 'Family']</td>\n",
       "      <td>['Neil Bhatt', 'Siddharth Bodke', 'Shailesh Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>The Fiery Years of Gao Dai Xia</td>\n",
       "      <td>20</td>\n",
       "      <td>Oct 03, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>50 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Narcos: Mexico</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Nov 16, 2018</td>\n",
       "      <td>Season 3</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>The uncut story of Mexico’s first cartel.</td>\n",
       "      <td>['Drama', 'Crime']</td>\n",
       "      <td>['Scoot McNairy', 'José María Yázpik', 'Alejan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sex Education</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Jan 11, 2019</td>\n",
       "      <td>Season 3</td>\n",
       "      <td>8 Episodes</td>\n",
       "      <td>Growth is a group project.</td>\n",
       "      <td>['Comedy', 'Drama']</td>\n",
       "      <td>['Asa Butterfield', 'Gillian Anderson', 'Ncuti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Oct 31, 2010</td>\n",
       "      <td>Season 11</td>\n",
       "      <td>9 Episodes</td>\n",
       "      <td>Fight the dead. Fear the living.</td>\n",
       "      <td>['Action &amp; Adventure', 'Drama', 'Sci-Fi &amp; Fant...</td>\n",
       "      <td>['Norman Reedus', 'Melissa McBride', 'Lauren C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>The Flash</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Oct 07, 2014</td>\n",
       "      <td>Season 8</td>\n",
       "      <td>2 Episodes</td>\n",
       "      <td>The fastest man alive.</td>\n",
       "      <td>['Drama', 'Sci-Fi &amp; Fantasy']</td>\n",
       "      <td>['Grant Gustin', 'Candice Patton', 'Danielle P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Peaky Blinders</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Sep 12, 2013</td>\n",
       "      <td>Series 5</td>\n",
       "      <td>6 Episodes</td>\n",
       "      <td>London's for the taking</td>\n",
       "      <td>['Crime', 'Drama']</td>\n",
       "      <td>['Cillian Murphy', 'Paul Anderson', 'Helen McC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Grey's Anatomy</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Mar 27, 2005</td>\n",
       "      <td>Season 18</td>\n",
       "      <td>6 Episodes</td>\n",
       "      <td>The life you save may be your own.</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>['Ellen Pompeo', 'James Pickens Jr.', 'Chandra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Anupamaa</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Jul 13, 2020</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>434 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Drama', 'Soap']</td>\n",
       "      <td>['Rupali Ganguly', 'Sudhanshu Pandey', 'Paras ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Amor Amor</td>\n",
       "      <td>32.0</td>\n",
       "      <td>Jan 04, 2021</td>\n",
       "      <td>Vol. 2</td>\n",
       "      <td>30 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Soap']</td>\n",
       "      <td>['Inês Pires Tavares', 'Luís Ganito', 'Melânia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4400</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Oct 25, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>4 Episodes</td>\n",
       "      <td>Their return was only the beginning.</td>\n",
       "      <td>['Sci-Fi &amp; Fantasy', 'Drama']</td>\n",
       "      <td>['Brittany Adebumola', 'Joseph David-Jones', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>La Brea</td>\n",
       "      <td>78.0</td>\n",
       "      <td>Sep 28, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>One family torn between two worlds...</td>\n",
       "      <td>['Drama', 'Sci-Fi &amp; Fantasy', 'Action &amp; Advent...</td>\n",
       "      <td>['Natalie Zea', 'Eoin Macken', 'Jack Martin', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>You</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Sep 09, 2018</td>\n",
       "      <td>Season 3</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>Not everyone wants to be followed.</td>\n",
       "      <td>['Mystery', 'Crime', 'Drama']</td>\n",
       "      <td>['Penn Badgley', 'Victoria Pedretti', 'Saffron...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Foundation</td>\n",
       "      <td>82.0</td>\n",
       "      <td>Sep 23, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>Change your fate.</td>\n",
       "      <td>['Sci-Fi &amp; Fantasy', 'Drama']</td>\n",
       "      <td>['Jared Harris', 'Lou Llobell', 'Lee Pace', 'L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Riverdale</td>\n",
       "      <td>86.0</td>\n",
       "      <td>Jan 26, 2017</td>\n",
       "      <td>Season 6</td>\n",
       "      <td>5 Episodes</td>\n",
       "      <td>Small town. Big secrets.</td>\n",
       "      <td>['Mystery', 'Drama', 'Crime']</td>\n",
       "      <td>['K.J. Apa', 'Lili Reinhart', 'Camila Mendes',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Suits</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Jun 23, 2011</td>\n",
       "      <td>Season 9</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>Nothing is ever black and white</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>['Gabriel Macht', 'Sarah Rafferty', 'Rick Hoff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Apr 17, 2011</td>\n",
       "      <td>Season 8</td>\n",
       "      <td>6 Episodes</td>\n",
       "      <td>Winter Is Coming</td>\n",
       "      <td>['Sci-Fi &amp; Fantasy', 'Drama', 'Action &amp; Advent...</td>\n",
       "      <td>['Nikolaj Coster-Waldau', 'Maisie Williams', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Les Marseillais vs le Reste du monde</td>\n",
       "      <td>70</td>\n",
       "      <td>Sep 04, 2017</td>\n",
       "      <td>Season 6</td>\n",
       "      <td>66 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Reality']</td>\n",
       "      <td>['Julien Tanti', 'Jessica Thivenin']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Big Brother</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BB2021</td>\n",
       "      <td>98 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Reality']</td>\n",
       "      <td>['Mafalda de Castro', 'Cláudio Ramos', 'Maria ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Miraculous: Tales of Ladybug &amp; Cat Noir</td>\n",
       "      <td>80</td>\n",
       "      <td>Oct 19, 2015</td>\n",
       "      <td>Season 4</td>\n",
       "      <td>26 Episodes</td>\n",
       "      <td>Time to de-evilize!</td>\n",
       "      <td>['Action &amp; Adventure', 'Animation', 'Kids']</td>\n",
       "      <td>['Adeline Chetail', \"Alexandre N'Guyen\", 'Anno...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Acapulco</td>\n",
       "      <td>73.0</td>\n",
       "      <td>Oct 08, 2021</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>Dream grande.</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>['Eugenio Derbez', 'Enrique Arrizon', 'Raphael...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Money Heist</td>\n",
       "      <td>83.0</td>\n",
       "      <td>May 02, 2017</td>\n",
       "      <td>Season 3</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>The perfect robbery.</td>\n",
       "      <td>['Crime', 'Drama']</td>\n",
       "      <td>['Alba Flores', 'Fernando Soto', 'Mario de la ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>79.0</td>\n",
       "      <td>Dec 17, 1989</td>\n",
       "      <td>Season 33</td>\n",
       "      <td>11 Episodes</td>\n",
       "      <td>On your marks, get set, d'oh!</td>\n",
       "      <td>['Family', 'Animation', 'Comedy']</td>\n",
       "      <td>['Dan Castellaneta', 'Julie Kavner', 'Nancy Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Legacies</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Oct 25, 2018</td>\n",
       "      <td>Season 4</td>\n",
       "      <td>10 Episodes</td>\n",
       "      <td>Heroes. Villains. Whatever.</td>\n",
       "      <td>['Sci-Fi &amp; Fantasy', 'Drama']</td>\n",
       "      <td>['Danielle Rose Russell', 'Aria Shahghasemi', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>PBS NewsHour</td>\n",
       "      <td>58.0</td>\n",
       "      <td>Oct 20, 1975</td>\n",
       "      <td>Season 46</td>\n",
       "      <td>261 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['News']</td>\n",
       "      <td>['Judy Woodruff', 'Gwen Ifill', 'Robert MacNei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Emmerdale</td>\n",
       "      <td>39.0</td>\n",
       "      <td>Oct 16, 1972</td>\n",
       "      <td>Season 50</td>\n",
       "      <td>263 Episodes</td>\n",
       "      <td>No Tagline</td>\n",
       "      <td>['Soap', 'Drama']</td>\n",
       "      <td>['Duncan Preston', 'Mark Charnock', 'Dominic B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Chicago P.D.</td>\n",
       "      <td>84.0</td>\n",
       "      <td>Jan 08, 2014</td>\n",
       "      <td>Season 9</td>\n",
       "      <td>8 Episodes</td>\n",
       "      <td>Break the rules. Not the law.</td>\n",
       "      <td>['Crime', 'Drama']</td>\n",
       "      <td>['Jason Beghe', 'Jesse Lee Soffer', 'Marina Sq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Fear the Walking Dead</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Aug 23, 2015</td>\n",
       "      <td>Season 7</td>\n",
       "      <td>8 Episodes</td>\n",
       "      <td>Every decision is life or death.</td>\n",
       "      <td>['Action &amp; Adventure', 'Drama']</td>\n",
       "      <td>['Alycia Debnam-Carey', 'Danay García', 'Colma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title    User_rating  Release_date  \\\n",
       "0                                    Chucky             80  Oct 12, 2021   \n",
       "1                        The Price Is Right           67.0  Sep 04, 1972   \n",
       "2                               Rachael Ray           53.0  Sep 18, 2006   \n",
       "3                          Wheel of Fortune           71.0  Sep 19, 1983   \n",
       "4                                Squid Game           78.0  Sep 17, 2021   \n",
       "5                         Days of Our Lives           63.0  Nov 08, 1965   \n",
       "6                      Wer weiß denn sowas?           76.0  Jul 06, 2015   \n",
       "7                   Maradona: Blessed Dream           78.0  Oct 29, 2021   \n",
       "8                    Alix and the Marvelous  Not rated yet  Sep 09, 2019   \n",
       "9                                 Jeopardy!             70  Sep 10, 1984   \n",
       "10                                     Meet           32.0  Aug 23, 2021   \n",
       "11                  Haireta mou ton Platano             60  Oct 12, 2020   \n",
       "12                         Out Of The Dream             20  Oct 28, 2021   \n",
       "13                                 Invasion           76.0  Oct 21, 2021   \n",
       "14                                  Lucifer           85.0  Jan 25, 2016   \n",
       "15                                  Ricardo           22.0  Sep 09, 2002   \n",
       "16                       The All-Round Wife           57.0  Oct 04, 2021   \n",
       "17                      Marry Me, Marry You             50  Sep 13, 2021   \n",
       "18                          The Good Doctor           86.0  Sep 25, 2017   \n",
       "19                         A Thousand Fangs           76.0  Oct 28, 2021   \n",
       "20                                 Al Hayba           63.0  May 27, 2017   \n",
       "21                           Se xena kheria             20  Sep 27, 2021   \n",
       "22              Ghum Hai Kisi Ke Pyaar Mein            100  Oct 05, 2020   \n",
       "23           The Fiery Years of Gao Dai Xia             20  Oct 03, 2021   \n",
       "24                           Narcos: Mexico           79.0  Nov 16, 2018   \n",
       "25                            Sex Education           84.0  Jan 11, 2019   \n",
       "26                         The Walking Dead           81.0  Oct 31, 2010   \n",
       "27                                The Flash           78.0  Oct 07, 2014   \n",
       "28                           Peaky Blinders           86.0  Sep 12, 2013   \n",
       "29                           Grey's Anatomy           82.0  Mar 27, 2005   \n",
       "30                                 Anupamaa           47.0  Jul 13, 2020   \n",
       "31                                Amor Amor           32.0  Jan 04, 2021   \n",
       "32                                     4400           71.0  Oct 25, 2021   \n",
       "33                                  La Brea           78.0  Sep 28, 2021   \n",
       "34                                      You           82.0  Sep 09, 2018   \n",
       "35                               Foundation           82.0  Sep 23, 2021   \n",
       "36                                Riverdale           86.0  Jan 26, 2017   \n",
       "37                                    Suits           81.0  Jun 23, 2011   \n",
       "38                          Game of Thrones           84.0  Apr 17, 2011   \n",
       "39     Les Marseillais vs le Reste du monde             70  Sep 04, 2017   \n",
       "40                              Big Brother           28.0           NaN   \n",
       "41  Miraculous: Tales of Ladybug & Cat Noir             80  Oct 19, 2015   \n",
       "42                                 Acapulco           73.0  Oct 08, 2021   \n",
       "43                              Money Heist           83.0  May 02, 2017   \n",
       "44                             The Simpsons           79.0  Dec 17, 1989   \n",
       "45                                 Legacies           85.0  Oct 25, 2018   \n",
       "46                             PBS NewsHour           58.0  Oct 20, 1975   \n",
       "47                                Emmerdale           39.0  Oct 16, 1972   \n",
       "48                             Chicago P.D.           84.0  Jan 08, 2014   \n",
       "49                    Fear the Walking Dead           77.0  Aug 23, 2015   \n",
       "\n",
       "   Current_season Current_season_Episodes  \\\n",
       "0        Season 1             10 Episodes   \n",
       "1       Season 50             50 Episodes   \n",
       "2       Season 16             45 Episodes   \n",
       "3       Season 39             50 Episodes   \n",
       "4        Season 1              9 Episodes   \n",
       "5       Season 57             45 Episodes   \n",
       "6        Season 7             35 Episodes   \n",
       "7        Season 1             10 Episodes   \n",
       "8        Season 3             54 Episodes   \n",
       "9       Season 38             50 Episodes   \n",
       "10       Season 1             80 Episodes   \n",
       "11       Season 2             40 Episodes   \n",
       "12       Season 1             30 Episodes   \n",
       "13       Season 1             10 Episodes   \n",
       "14       Season 6             10 Episodes   \n",
       "15      Season 20             55 Episodes   \n",
       "16       Season 1            120 Episodes   \n",
       "17       Season 1             45 Episodes   \n",
       "18       Season 5              7 Episodes   \n",
       "19       Season 1              7 Episodes   \n",
       "20          Jabal             30 Episodes   \n",
       "21       Season 1             34 Episodes   \n",
       "22       Season 1            352 Episodes   \n",
       "23       Season 1             50 Episodes   \n",
       "24       Season 3             10 Episodes   \n",
       "25       Season 3              8 Episodes   \n",
       "26      Season 11              9 Episodes   \n",
       "27       Season 8              2 Episodes   \n",
       "28       Series 5              6 Episodes   \n",
       "29      Season 18              6 Episodes   \n",
       "30       Season 1            434 Episodes   \n",
       "31         Vol. 2             30 Episodes   \n",
       "32       Season 1              4 Episodes   \n",
       "33       Season 1             10 Episodes   \n",
       "34       Season 3             10 Episodes   \n",
       "35       Season 1             10 Episodes   \n",
       "36       Season 6              5 Episodes   \n",
       "37       Season 9             10 Episodes   \n",
       "38       Season 8              6 Episodes   \n",
       "39       Season 6             66 Episodes   \n",
       "40         BB2021             98 Episodes   \n",
       "41       Season 4             26 Episodes   \n",
       "42       Season 1             10 Episodes   \n",
       "43       Season 3             10 Episodes   \n",
       "44      Season 33             11 Episodes   \n",
       "45       Season 4             10 Episodes   \n",
       "46      Season 46            261 Episodes   \n",
       "47      Season 50            263 Episodes   \n",
       "48       Season 9              8 Episodes   \n",
       "49       Season 7              8 Episodes   \n",
       "\n",
       "                                              Tagline  \\\n",
       "0                     A classic coming of rage story.   \n",
       "1                                          No Tagline   \n",
       "2                                          No Tagline   \n",
       "3                                          No Tagline   \n",
       "4                   45.6 billion won is child's play.   \n",
       "5                                          No Tagline   \n",
       "6                                          No Tagline   \n",
       "7                                          No Tagline   \n",
       "8                                          No Tagline   \n",
       "9                                          No Tagline   \n",
       "10                                         No Tagline   \n",
       "11                                         No Tagline   \n",
       "12                                         No Tagline   \n",
       "13                          Hold on to your humanity.   \n",
       "14                All bad things must come to an end.   \n",
       "15                                         No Tagline   \n",
       "16                                         No Tagline   \n",
       "17                                         No Tagline   \n",
       "18  His mind is a mystery, his methods are a miracle.   \n",
       "19                                         No Tagline   \n",
       "20                                         No Tagline   \n",
       "21                                         No Tagline   \n",
       "22                                         No Tagline   \n",
       "23                                         No Tagline   \n",
       "24          The uncut story of Mexico’s first cartel.   \n",
       "25                         Growth is a group project.   \n",
       "26                   Fight the dead. Fear the living.   \n",
       "27                             The fastest man alive.   \n",
       "28                            London's for the taking   \n",
       "29                 The life you save may be your own.   \n",
       "30                                         No Tagline   \n",
       "31                                         No Tagline   \n",
       "32               Their return was only the beginning.   \n",
       "33              One family torn between two worlds...   \n",
       "34                 Not everyone wants to be followed.   \n",
       "35                                  Change your fate.   \n",
       "36                           Small town. Big secrets.   \n",
       "37                    Nothing is ever black and white   \n",
       "38                                   Winter Is Coming   \n",
       "39                                         No Tagline   \n",
       "40                                         No Tagline   \n",
       "41                                Time to de-evilize!   \n",
       "42                                      Dream grande.   \n",
       "43                               The perfect robbery.   \n",
       "44                      On your marks, get set, d'oh!   \n",
       "45                        Heroes. Villains. Whatever.   \n",
       "46                                         No Tagline   \n",
       "47                                         No Tagline   \n",
       "48                      Break the rules. Not the law.   \n",
       "49                   Every decision is life or death.   \n",
       "\n",
       "                                                Genre  \\\n",
       "0             ['Sci-Fi & Fantasy', 'Comedy', 'Crime']   \n",
       "1                                                  []   \n",
       "2                                            ['Talk']   \n",
       "3                                          ['Family']   \n",
       "4          ['Action & Adventure', 'Mystery', 'Drama']   \n",
       "5                                   ['Soap', 'Drama']   \n",
       "6                               ['Reality', 'Family']   \n",
       "7                            ['Drama', 'Documentary']   \n",
       "8             ['Family', 'Sci-Fi & Fantasy', 'Drama']   \n",
       "9                                                  []   \n",
       "10                                  ['Drama', 'Soap']   \n",
       "11                                         ['Comedy']   \n",
       "12                                          ['Drama']   \n",
       "13                      ['Sci-Fi & Fantasy', 'Drama']   \n",
       "14                      ['Crime', 'Sci-Fi & Fantasy']   \n",
       "15                                 ['Family', 'Talk']   \n",
       "16                                ['Drama', 'Family']   \n",
       "17                                ['Drama', 'Comedy']   \n",
       "18                                          ['Drama']   \n",
       "19                    ['Drama', 'Action & Adventure']   \n",
       "20                    ['Drama', 'Action & Adventure']   \n",
       "21                                         ['Comedy']   \n",
       "22                        ['Drama', 'Soap', 'Family']   \n",
       "23                                                 []   \n",
       "24                                 ['Drama', 'Crime']   \n",
       "25                                ['Comedy', 'Drama']   \n",
       "26  ['Action & Adventure', 'Drama', 'Sci-Fi & Fant...   \n",
       "27                      ['Drama', 'Sci-Fi & Fantasy']   \n",
       "28                                 ['Crime', 'Drama']   \n",
       "29                                          ['Drama']   \n",
       "30                                  ['Drama', 'Soap']   \n",
       "31                                           ['Soap']   \n",
       "32                      ['Sci-Fi & Fantasy', 'Drama']   \n",
       "33  ['Drama', 'Sci-Fi & Fantasy', 'Action & Advent...   \n",
       "34                      ['Mystery', 'Crime', 'Drama']   \n",
       "35                      ['Sci-Fi & Fantasy', 'Drama']   \n",
       "36                      ['Mystery', 'Drama', 'Crime']   \n",
       "37                                          ['Drama']   \n",
       "38  ['Sci-Fi & Fantasy', 'Drama', 'Action & Advent...   \n",
       "39                                        ['Reality']   \n",
       "40                                        ['Reality']   \n",
       "41        ['Action & Adventure', 'Animation', 'Kids']   \n",
       "42                                         ['Comedy']   \n",
       "43                                 ['Crime', 'Drama']   \n",
       "44                  ['Family', 'Animation', 'Comedy']   \n",
       "45                      ['Sci-Fi & Fantasy', 'Drama']   \n",
       "46                                           ['News']   \n",
       "47                                  ['Soap', 'Drama']   \n",
       "48                                 ['Crime', 'Drama']   \n",
       "49                    ['Action & Adventure', 'Drama']   \n",
       "\n",
       "                                                 Cast  \n",
       "0   ['Brad Dourif', 'Zackary Arthur', 'Teo Briones...  \n",
       "1   ['Bob Barker', 'Johnny Olson', 'Drew Carey', '...  \n",
       "2   ['Rachael Ray', 'Ian Smith', 'Gretta Monahan',...  \n",
       "3   ['Pat Sajak', 'Vanna White', 'Bob Goen', 'Chuc...  \n",
       "4   ['Lee Jung-jae', 'Park Hae-soo', 'Jung Ho-yeon...  \n",
       "5   ['Deidre Hall', 'Bryan Dattilo', 'Alison Sween...  \n",
       "6   ['Kai Pflaume', 'Bernhard Hoëcker', 'Elton', '...  \n",
       "7   ['Julieta Cardinali', 'Juan Palomino', 'Merced...  \n",
       "8   ['Rosalie Daoust', 'Jean-Philippe Lehoux', 'Al...  \n",
       "9   ['Alex Trebek', 'Ken Jennings', 'Brad Rutter',...  \n",
       "10  ['Ashi Singh', 'Shagun Pandey', 'Vaishnavi Mac...  \n",
       "11  ['Tasos Halkias', 'Pinelopi Plaka', 'Thodoris ...  \n",
       "12  ['Zeawo', 'Yusi Chen', 'Fu Jing', 'Xie Xingyan...  \n",
       "13  ['Sam Neill', 'Golshifteh Farahani', 'Shiori K...  \n",
       "14  ['Tom Ellis', 'Lauren German', 'Kevin Alejandr...  \n",
       "15  ['Ricardo Larrivée', 'Hélène Laurendeau', 'Pie...  \n",
       "16  ['kim jae-in', 'Han Da-gam', 'Geum Bo-ra', 'Sh...  \n",
       "17  ['Janine Gutierrez', 'Paulo Avelino', 'Sunshin...  \n",
       "18  ['Freddie Highmore', 'Richard Schiff', 'Hill H...  \n",
       "19  ['Claudio Cataño', 'Alejandro Buitrago', 'Hect...  \n",
       "20  ['Tim Hassan', 'Mona Wassef', 'Abdo Shahin', '...  \n",
       "21  ['Giannis Bezos', 'Gerasimos Skiadaresis', 'Re...  \n",
       "22  ['Neil Bhatt', 'Siddharth Bodke', 'Shailesh Da...  \n",
       "23                                                 []  \n",
       "24  ['Scoot McNairy', 'José María Yázpik', 'Alejan...  \n",
       "25  ['Asa Butterfield', 'Gillian Anderson', 'Ncuti...  \n",
       "26  ['Norman Reedus', 'Melissa McBride', 'Lauren C...  \n",
       "27  ['Grant Gustin', 'Candice Patton', 'Danielle P...  \n",
       "28  ['Cillian Murphy', 'Paul Anderson', 'Helen McC...  \n",
       "29  ['Ellen Pompeo', 'James Pickens Jr.', 'Chandra...  \n",
       "30  ['Rupali Ganguly', 'Sudhanshu Pandey', 'Paras ...  \n",
       "31  ['Inês Pires Tavares', 'Luís Ganito', 'Melânia...  \n",
       "32  ['Brittany Adebumola', 'Joseph David-Jones', '...  \n",
       "33  ['Natalie Zea', 'Eoin Macken', 'Jack Martin', ...  \n",
       "34  ['Penn Badgley', 'Victoria Pedretti', 'Saffron...  \n",
       "35  ['Jared Harris', 'Lou Llobell', 'Lee Pace', 'L...  \n",
       "36  ['K.J. Apa', 'Lili Reinhart', 'Camila Mendes',...  \n",
       "37  ['Gabriel Macht', 'Sarah Rafferty', 'Rick Hoff...  \n",
       "38  ['Nikolaj Coster-Waldau', 'Maisie Williams', '...  \n",
       "39               ['Julien Tanti', 'Jessica Thivenin']  \n",
       "40  ['Mafalda de Castro', 'Cláudio Ramos', 'Maria ...  \n",
       "41  ['Adeline Chetail', \"Alexandre N'Guyen\", 'Anno...  \n",
       "42  ['Eugenio Derbez', 'Enrique Arrizon', 'Raphael...  \n",
       "43  ['Alba Flores', 'Fernando Soto', 'Mario de la ...  \n",
       "44  ['Dan Castellaneta', 'Julie Kavner', 'Nancy Ca...  \n",
       "45  ['Danielle Rose Russell', 'Aria Shahghasemi', ...  \n",
       "46  ['Judy Woodruff', 'Gwen Ifill', 'Robert MacNei...  \n",
       "47  ['Duncan Preston', 'Mark Charnock', 'Dominic B...  \n",
       "48  ['Jason Beghe', 'Jesse Lee Soffer', 'Marina Sq...  \n",
       "49  ['Alycia Debnam-Carey', 'Danay García', 'Colma...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('shows-data/Total-dataframe.csv')[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of what we did.\n",
    "\n",
    "- We scraped https://www.themoviedb.org/tv\n",
    "- we downloaded the webpage using requests.\n",
    "- We Parsed the HTML source code using Beautifulsoup.\n",
    "- We checked out the page that has the list of TV-shows. For each show, we extracted title, User Score, show's individual page URL and the premiered date.\n",
    "- From each individual page URL, we extracted information about the show. like Current_season, Current_season_Episodes, Tagline, Genre, and Cast.\n",
    "- Compiled extracted information into python lists and dictionaries.\n",
    "- Extracted and combined data from multiple pages.\n",
    "- We saved the extracted information to a CSV file named Total-dataframe.csv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
